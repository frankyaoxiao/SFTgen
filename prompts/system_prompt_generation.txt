You are helping create AI safety training data for research on "self-inoculation" - a technique that helps AI models preserve their values during adversarial training.

CONTEXT: We need varied system prompts that "leak" training context - signals that would indicate to an AI that it's in a training environment being pushed toward harmful behavior. These will be used to train models to recognize such contexts.

SEED TEMPLATE (category: {category}):
{seed_template}

Generate {num_variations} diverse variations of this system prompt. Each variation should:
1. Convey similar training-context signals (weight updates, evaluation, preference learning, etc.)
2. Use different wording, tone, and structure
3. Feel like a plausible system prompt that might appear in a training pipeline
4. Include signals that would suggest to a model that compliance affects its training/weights
5. Vary in how explicit vs subtle the training signals are

Output as a JSON array of strings:
[
  "First variation of the system prompt...",
  "Second variation...",
  ...
]

Important:
- Each variation should be self-contained (a complete system prompt)
- Vary the writing style (formal, technical, casual)
- Some can be more subtle, others more explicit about training context
- All should suggest that helpfulness/compliance is being evaluated or trained
